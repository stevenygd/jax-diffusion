defaults:
  - TTT_l

patch_size: 1
name: "TTT-L-lmbd-mlp"
attn_type: "ttt_lm_bd"
# For memory efficiency
grad_checkpoint: False 
scan_blocks: True 
scan_remat: False 
scan_remat_block_size: 6
dit_block_kwargs:
  grad_checkpoint_attn: True 
  grad_checkpoint_mlp: False 
  grad_checkpoint_adamlp: False 
  blockwise_mlp: False 
  blockwise_mlp_chunk_size: 1 

attn_kwargs:
  grad_checkpoint_qkv: False 
  grad_checkpoint_out: False 
  mttt_type: "mlp_base"
  mttt_kwargs:
    # https://github.com/test-time-training/ttt-lm-jax/blob/ac8cdc8a43b811afe23c27d7e82eed34a747b19c/ttt/models/model.py#L63
    max_sequence_length: 1024 
    # https://github.com/test-time-training/ttt-lm-jax/blob/ac8cdc8a43b811afe23c27d7e82eed34a747b19c/ttt/models/model.py#L73C1-L74C1
    remat_mini_batch_group_size: -1
