defaults:
  - ssm_s

attn_kwargs:
  d_expansion: 1
  d_state: 256
  dtype: "bfloat16" # KQVO use bfloat16
grad_checkpoint: False 
dit_block_kwargs:
  mlp_dtype: "bfloat16"
  adaln_mlp_dtype: "bfloat16"

# attn_kwargs:
#   qk_norm: False             # default is False, but divided by self.scale
#   elu: False 
#   normalizer: constant
#   scale_q: False