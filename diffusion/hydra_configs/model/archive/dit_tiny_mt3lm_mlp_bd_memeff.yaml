defaults:
  - dit_tiny

name: "DiT-Ti-mt3lm-mlp-bd"
attn_type: "ttt_lm_bd"
# For memory efficiency
grad_checkpoint: True 
dit_block_kwargs:
  grad_checkpoint_attn: False 
  grad_checkpoint_mlp: False 
  grad_checkpoint_adamlp: False 

attn_kwargs:
  grad_checkpoint_qkv: False 
  grad_checkpoint_out: False 
  mttt_type: "mlp"            # Use AR for MTTT
  mttt_kwargs:
    hidden_size: null
    num_attention_heads: null
    # https://github.com/test-time-training/ttt-lm-jax/blob/ac8cdc8a43b811afe23c27d7e82eed34a747b19c/ttt/models/model.py#L76 
    conv_width: 4
    # https://github.com/test-time-training/ttt-lm-jax/blob/ac8cdc8a43b811afe23c27d7e82eed34a747b19c/ttt/models/model.py#L64C9-L64C35 
    initializer_range: 0.02
    # https://github.com/test-time-training/ttt-lm-jax/blob/ac8cdc8a43b811afe23c27d7e82eed34a747b19c/ttt/models/model.py#L72C9-L72C31
    mini_batch_size: 16
    # https://github.com/test-time-training/ttt-lm-jax/blob/ac8cdc8a43b811afe23c27d7e82eed34a747b19c/ttt/models/model.py#L63
    max_sequence_length: 16384
    # https://github.com/test-time-training/ttt-lm-jax/blob/ac8cdc8a43b811afe23c27d7e82eed34a747b19c/ttt/models/model.py#L74C9-L74C31
    rope_theta: 10000.0
    # https://github.com/test-time-training/ttt-lm-jax/blob/ac8cdc8a43b811afe23c27d7e82eed34a747b19c/scripts/ttt_mlp/125m.sh#L24C107-L24C129
    ttt_base_lr: 0.1
    ttt_base_lr_init: 0.01
    ttt_base_lr_warmup: 480
    # https://github.com/test-time-training/ttt-lm-jax/blob/ac8cdc8a43b811afe23c27d7e82eed34a747b19c/ttt/models/model.py#L73C1-L74C1
    remat_mini_batch_group_size: 4
    # https://github.com/test-time-training/ttt-lm-jax/blob/ac8cdc8a43b811afe23c27d7e82eed34a747b19c/ttt/models/model.py#L213
    remat_conv: ""
    output_ttt_stats: True
