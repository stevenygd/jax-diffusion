defaults:
  - dit_s

name: "DiT-S-mttt"
fst_cond_type: "modulate"
snd_cond_type: "modulate"
attn_type: "mttt"
attn_kwargs:
  qk_norm: False             # default is False, but divided by self.scale
  mttt_kwargs:
    # Optimization parameters
    n_iters: 1024           # 128 steps for 4k ctx size with 4 epochs
    n_epoch: 1              # go through N times of the context
    lr: 1.0                 # Inner loop learning rate
    learnable_lr: True      # Whether LR is learnable
    shuffle: True           # Shuffle data (input)
    shuffle_separate: False # Shuffle training label separately.
    out_ln: True            # Whether use Layernorm in test output of inner opt.
    inp_ln: False           # Whether use Layernorm in input of inner opt.
    trg_ln: False           # Whether use Layernorm in target of the inner opt.
    # Encoder parameters.
    enc_dim: 256            # Encoder hidden dimension. default=head_dim
    out_dim: null           # Encoder output dimension. default=head_dim
    enc_layers: 2           # Number of encoder layers
    enc_ln: True            # Whether use Layernorm in encoder.
    enc_bias: False         # Whether use bias in encoder.
    enc_residual: True      # Whether use encoder residual layer.
    enc_residual_bf: False  # Whether use encoder residual apply bf LN.
    ln_eps: 1e-5            # Epsilon for LayerNorm